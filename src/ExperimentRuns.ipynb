{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "from dataLoader import DataLoader\n",
    "from modelLoader import ModelLoader\n",
    "from time import time\n",
    "from utils import buildRunName\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Debugging info\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint experiment\n",
    "- Train model over 50 epochs\n",
    "- Save weights every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment:\n",
    "#   Train model over 50 epochs\n",
    "#   Save weights every epoch\n",
    "\n",
    "#Params\n",
    "dataDir = \"../data/\"\n",
    "imgHeight = 224\n",
    "imgWidth = 224\n",
    "batchSizes = [32]\n",
    "\n",
    "shuffleSeed = 123\n",
    "\n",
    "transferLearning = False\n",
    "\n",
    "epochCounts = [50]\n",
    "\n",
    "currentBatchSize = batchSizes[0]\n",
    "currentEpochCount = epochCounts[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15561 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Constants & Utils\n",
    "modelName = \"MobileNetV1_CheckpointTest\"\n",
    "train_ds, val_ds, _ = DataLoader().loadDatasets(dataDir, currentBatchSize)\n",
    "model = ModelLoader().loadMobileNetV1(train_ds, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel():\n",
    "    print(f'-------- Now Training: {buildRunName(modelName, transferLearning, currentEpochCount, currentBatchSize)} --------')\n",
    "    #checkpoint_baseDir = \"../models/checkpoints/\" + buildRunName(modelName, transferLearning, currentEpochCount, currentBatchSize)\n",
    "    #os.makedirs(checkpoint_baseDir)\n",
    "    #checkpoint_filepath = checkpoint_baseDir + \"/{epoch:02d}.hdf5\"\n",
    "    train_ds, val_ds, _ = DataLoader().loadDatasets(dataDir, currentBatchSize)\n",
    "    start_time = time()\n",
    "    model = ModelLoader().loadMobileNetV1(train_ds, transferLearning, not transferLearning)\n",
    "    \n",
    "    log_dir = \"../logs/fit/\" + buildRunName(modelName, transferLearning, currentEpochCount, currentBatchSize)\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    \n",
    "    #model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    #    filepath=checkpoint_filepath,\n",
    "    #    save_weights_only=True)\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy', tf.keras.metrics.FalseNegatives(), tf.keras.metrics.FalsePositives()])\n",
    "    model.fit(train_ds,\n",
    "                    epochs=currentEpochCount,\n",
    "                    validation_data=val_ds,\n",
    "                    callbacks=[tensorboard_callback])\n",
    "    model.save(\"../models/\" + buildRunName(modelName, transferLearning, currentEpochCount, currentBatchSize))\n",
    "    end_time = time()\n",
    "    \n",
    "    f = open(\"../logs/RunTimer_CheckpointTest.txt\", \"a\")\n",
    "    f.write(f'{end_time - start_time};{buildRunName(modelName, transferLearning, currentEpochCount, currentBatchSize)}\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Now Training: MobileNetV1_CheckpointTest_scratch_epochs-50_batch-32 --------\n",
      "Found 15561 files belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "341/341 [==============================] - 91s 209ms/step - loss: 0.3509 - accuracy: 0.8452 - false_negatives_2: 834.0000 - false_positives_2: 852.0000 - val_loss: 0.7161 - val_accuracy: 0.5463 - val_false_negatives_2: 0.0000e+00 - val_false_positives_2: 1059.0000\n",
      "Epoch 2/50\n",
      "341/341 [==============================] - 90s 211ms/step - loss: 0.1786 - accuracy: 0.9309 - false_negatives_2: 428.0000 - false_positives_2: 325.0000 - val_loss: 0.3632 - val_accuracy: 0.8171 - val_false_negatives_2: 399.0000 - val_false_positives_2: 28.0000\n",
      "Epoch 3/50\n",
      "341/341 [==============================] - 91s 214ms/step - loss: 0.1427 - accuracy: 0.9468 - false_negatives_2: 338.0000 - false_positives_2: 241.0000 - val_loss: 0.5417 - val_accuracy: 0.8320 - val_false_negatives_2: 5.0000 - val_false_positives_2: 387.0000\n",
      "Epoch 4/50\n",
      "341/341 [==============================] - 93s 216ms/step - loss: 0.1177 - accuracy: 0.9579 - false_negatives_2: 271.0000 - false_positives_2: 188.0000 - val_loss: 0.1952 - val_accuracy: 0.9302 - val_false_negatives_2: 149.0000 - val_false_positives_2: 14.0000\n",
      "Epoch 5/50\n",
      "341/341 [==============================] - 97s 227ms/step - loss: 0.0916 - accuracy: 0.9667 - false_negatives_2: 209.0000 - false_positives_2: 154.0000 - val_loss: 0.0981 - val_accuracy: 0.9632 - val_false_negatives_2: 11.0000 - val_false_positives_2: 75.0000\n",
      "Epoch 6/50\n",
      "341/341 [==============================] - 96s 222ms/step - loss: 0.0868 - accuracy: 0.9684 - false_negatives_2: 211.0000 - false_positives_2: 133.0000 - val_loss: 0.2329 - val_accuracy: 0.9177 - val_false_negatives_2: 3.0000 - val_false_positives_2: 189.0000\n",
      "Epoch 7/50\n",
      "341/341 [==============================] - 100s 228ms/step - loss: 0.0682 - accuracy: 0.9754 - false_negatives_2: 156.0000 - false_positives_2: 112.0000 - val_loss: 0.1501 - val_accuracy: 0.9452 - val_false_negatives_2: 3.0000 - val_false_positives_2: 125.0000\n",
      "Epoch 8/50\n",
      "341/341 [==============================] - 103s 236ms/step - loss: 0.0635 - accuracy: 0.9766 - false_negatives_2: 144.0000 - false_positives_2: 111.0000 - val_loss: 0.3018 - val_accuracy: 0.9242 - val_false_negatives_2: 6.0000 - val_false_positives_2: 171.0000\n",
      "Epoch 9/50\n",
      "341/341 [==============================] - 107s 241ms/step - loss: 0.0642 - accuracy: 0.9765 - false_negatives_2: 149.0000 - false_positives_2: 107.0000 - val_loss: 0.1575 - val_accuracy: 0.9374 - val_false_negatives_2: 4.0000 - val_false_positives_2: 142.0000\n",
      "Epoch 10/50\n",
      "341/341 [==============================] - 110s 247ms/step - loss: 0.0502 - accuracy: 0.9821 - false_negatives_2: 112.0000 - false_positives_2: 83.0000 - val_loss: 0.2121 - val_accuracy: 0.9297 - val_false_negatives_2: 3.0000 - val_false_positives_2: 161.0000\n",
      "Epoch 11/50\n",
      "341/341 [==============================] - 113s 252ms/step - loss: 0.0546 - accuracy: 0.9806 - false_negatives_2: 124.0000 - false_positives_2: 87.0000 - val_loss: 0.0678 - val_accuracy: 0.9756 - val_false_negatives_2: 5.0000 - val_false_positives_2: 52.0000\n",
      "Epoch 12/50\n",
      "341/341 [==============================] - 118s 259ms/step - loss: 0.0528 - accuracy: 0.9798 - false_negatives_2: 127.0000 - false_positives_2: 93.0000 - val_loss: 0.0534 - val_accuracy: 0.9794 - val_false_negatives_2: 10.0000 - val_false_positives_2: 38.0000\n",
      "Epoch 13/50\n",
      "341/341 [==============================] - 121s 268ms/step - loss: 0.0433 - accuracy: 0.9849 - false_negatives_2: 96.0000 - false_positives_2: 69.0000 - val_loss: 0.1619 - val_accuracy: 0.9344 - val_false_negatives_2: 3.0000 - val_false_positives_2: 150.0000\n",
      "Epoch 14/50\n",
      "341/341 [==============================] - 123s 269ms/step - loss: 0.0385 - accuracy: 0.9875 - false_negatives_2: 83.0000 - false_positives_2: 53.0000 - val_loss: 0.0537 - val_accuracy: 0.9807 - val_false_negatives_2: 11.0000 - val_false_positives_2: 34.0000\n",
      "Epoch 15/50\n",
      "341/341 [==============================] - 128s 276ms/step - loss: 0.0483 - accuracy: 0.9837 - false_negatives_2: 101.0000 - false_positives_2: 76.0000 - val_loss: 0.3036 - val_accuracy: 0.9340 - val_false_negatives_2: 2.0000 - val_false_positives_2: 152.0000\n",
      "Epoch 16/50\n",
      "341/341 [==============================] - 131s 284ms/step - loss: 0.0395 - accuracy: 0.9859 - false_negatives_2: 96.0000 - false_positives_2: 58.0000 - val_loss: 0.0192 - val_accuracy: 0.9936 - val_false_negatives_2: 6.0000 - val_false_positives_2: 9.0000\n",
      "Epoch 17/50\n",
      "341/341 [==============================] - 134s 290ms/step - loss: 0.0381 - accuracy: 0.9872 - false_negatives_2: 81.0000 - false_positives_2: 58.0000 - val_loss: 0.0583 - val_accuracy: 0.9790 - val_false_negatives_2: 8.0000 - val_false_positives_2: 41.0000\n",
      "Epoch 18/50\n",
      "341/341 [==============================] - 137s 293ms/step - loss: 0.0323 - accuracy: 0.9881 - false_negatives_2: 73.0000 - false_positives_2: 57.0000 - val_loss: 0.0107 - val_accuracy: 0.9974 - val_false_negatives_2: 4.0000 - val_false_positives_2: 2.0000\n",
      "Epoch 19/50\n",
      "341/341 [==============================] - 139s 298ms/step - loss: 0.0302 - accuracy: 0.9882 - false_negatives_2: 72.0000 - false_positives_2: 56.0000 - val_loss: 0.1551 - val_accuracy: 0.9477 - val_false_negatives_2: 5.0000 - val_false_positives_2: 117.0000\n",
      "Epoch 20/50\n",
      "341/341 [==============================] - 142s 305ms/step - loss: 0.0264 - accuracy: 0.9905 - false_negatives_2: 54.0000 - false_positives_2: 49.0000 - val_loss: 0.0562 - val_accuracy: 0.9777 - val_false_negatives_2: 1.0000 - val_false_positives_2: 51.0000\n",
      "Epoch 21/50\n",
      "341/341 [==============================] - 145s 309ms/step - loss: 0.0317 - accuracy: 0.9887 - false_negatives_2: 73.0000 - false_positives_2: 50.0000 - val_loss: 0.0592 - val_accuracy: 0.9790 - val_false_negatives_2: 46.0000 - val_false_positives_2: 3.0000\n",
      "Epoch 22/50\n",
      "341/341 [==============================] - 146s 311ms/step - loss: 0.0237 - accuracy: 0.9922 - false_negatives_2: 50.0000 - false_positives_2: 35.0000 - val_loss: 0.0373 - val_accuracy: 0.9893 - val_false_negatives_2: 6.0000 - val_false_positives_2: 19.0000\n",
      "Epoch 23/50\n",
      "341/341 [==============================] - 152s 317ms/step - loss: 0.0275 - accuracy: 0.9899 - false_negatives_2: 66.0000 - false_positives_2: 44.0000 - val_loss: 0.0184 - val_accuracy: 0.9927 - val_false_negatives_2: 13.0000 - val_false_positives_2: 4.0000\n",
      "Epoch 24/50\n",
      "341/341 [==============================] - 152s 321ms/step - loss: 0.0256 - accuracy: 0.9910 - false_negatives_2: 56.0000 - false_positives_2: 42.0000 - val_loss: 0.0470 - val_accuracy: 0.9871 - val_false_negatives_2: 0.0000e+00 - val_false_positives_2: 30.0000\n",
      "Epoch 25/50\n",
      "341/341 [==============================] - 155s 326ms/step - loss: 0.0240 - accuracy: 0.9901 - false_negatives_2: 59.0000 - false_positives_2: 49.0000 - val_loss: 0.0488 - val_accuracy: 0.9807 - val_false_negatives_2: 14.0000 - val_false_positives_2: 31.0000\n",
      "Epoch 26/50\n",
      "341/341 [==============================] - 158s 334ms/step - loss: 0.0228 - accuracy: 0.9931 - false_negatives_2: 45.0000 - false_positives_2: 30.0000 - val_loss: 0.0098 - val_accuracy: 0.9979 - val_false_negatives_2: 2.0000 - val_false_positives_2: 3.0000\n",
      "Epoch 27/50\n",
      "341/341 [==============================] - 159s 334ms/step - loss: 0.0164 - accuracy: 0.9944 - false_negatives_2: 36.0000 - false_positives_2: 25.0000 - val_loss: 0.2287 - val_accuracy: 0.9447 - val_false_negatives_2: 0.0000e+00 - val_false_positives_2: 129.0000\n",
      "Epoch 28/50\n",
      "341/341 [==============================] - 159s 331ms/step - loss: 0.0141 - accuracy: 0.9941 - false_negatives_2: 39.0000 - false_positives_2: 25.0000 - val_loss: 0.0236 - val_accuracy: 0.9897 - val_false_negatives_2: 18.0000 - val_false_positives_2: 6.0000\n",
      "Epoch 29/50\n",
      "341/341 [==============================] - 162s 339ms/step - loss: 0.0269 - accuracy: 0.9914 - false_negatives_2: 53.0000 - false_positives_2: 41.0000 - val_loss: 0.1266 - val_accuracy: 0.9632 - val_false_negatives_2: 83.0000 - val_false_positives_2: 3.0000\n",
      "Epoch 30/50\n",
      "341/341 [==============================] - 164s 338ms/step - loss: 0.0223 - accuracy: 0.9912 - false_negatives_2: 54.0000 - false_positives_2: 42.0000 - val_loss: 0.0248 - val_accuracy: 0.9914 - val_false_negatives_2: 7.0000 - val_false_positives_2: 13.0000\n",
      "Epoch 31/50\n",
      "341/341 [==============================] - 166s 342ms/step - loss: 0.0117 - accuracy: 0.9957 - false_negatives_2: 31.0000 - false_positives_2: 16.0000 - val_loss: 0.0030 - val_accuracy: 0.9996 - val_false_negatives_2: 1.0000 - val_false_positives_2: 0.0000e+00\n",
      "Epoch 32/50\n",
      "341/341 [==============================] - 166s 344ms/step - loss: 0.0141 - accuracy: 0.9954 - false_negatives_2: 28.0000 - false_positives_2: 22.0000 - val_loss: 0.0093 - val_accuracy: 0.9966 - val_false_negatives_2: 8.0000 - val_false_positives_2: 0.0000e+00\n",
      "Epoch 33/50\n",
      "341/341 [==============================] - 168s 349ms/step - loss: 0.0081 - accuracy: 0.9970 - false_negatives_2: 22.0000 - false_positives_2: 11.0000 - val_loss: 0.1009 - val_accuracy: 0.9781 - val_false_negatives_2: 47.0000 - val_false_positives_2: 4.0000\n",
      "Epoch 34/50\n",
      "341/341 [==============================] - 170s 353ms/step - loss: 0.0174 - accuracy: 0.9938 - false_negatives_2: 40.0000 - false_positives_2: 28.0000 - val_loss: 0.0087 - val_accuracy: 0.9961 - val_false_negatives_2: 7.0000 - val_false_positives_2: 2.0000\n",
      "Epoch 35/50\n",
      "341/341 [==============================] - 171s 354ms/step - loss: 0.0100 - accuracy: 0.9968 - false_negatives_2: 22.0000 - false_positives_2: 13.0000 - val_loss: 0.0107 - val_accuracy: 0.9983 - val_false_negatives_2: 0.0000e+00 - val_false_positives_2: 4.0000\n",
      "Epoch 36/50\n",
      "341/341 [==============================] - 176s 366ms/step - loss: 0.0154 - accuracy: 0.9946 - false_negatives_2: 32.0000 - false_positives_2: 27.0000 - val_loss: 0.0056 - val_accuracy: 0.9979 - val_false_negatives_2: 5.0000 - val_false_positives_2: 0.0000e+00\n",
      "Epoch 37/50\n",
      "341/341 [==============================] - 176s 358ms/step - loss: 0.0118 - accuracy: 0.9954 - false_negatives_2: 27.0000 - false_positives_2: 23.0000 - val_loss: 0.0369 - val_accuracy: 0.9867 - val_false_negatives_2: 1.0000 - val_false_positives_2: 30.0000\n",
      "Epoch 38/50\n",
      "341/341 [==============================] - 172s 355ms/step - loss: 0.0085 - accuracy: 0.9969 - false_negatives_2: 16.0000 - false_positives_2: 18.0000 - val_loss: 0.0331 - val_accuracy: 0.9889 - val_false_negatives_2: 10.0000 - val_false_positives_2: 16.0000\n",
      "Epoch 39/50\n",
      "341/341 [==============================] - 173s 357ms/step - loss: 0.0143 - accuracy: 0.9945 - false_negatives_2: 36.0000 - false_positives_2: 24.0000 - val_loss: 0.0669 - val_accuracy: 0.9756 - val_false_negatives_2: 0.0000e+00 - val_false_positives_2: 57.0000\n",
      "Epoch 40/50\n",
      "341/341 [==============================] - 174s 359ms/step - loss: 0.0124 - accuracy: 0.9953 - false_negatives_2: 26.0000 - false_positives_2: 25.0000 - val_loss: 0.0053 - val_accuracy: 0.9983 - val_false_negatives_2: 4.0000 - val_false_positives_2: 0.0000e+00\n",
      "Epoch 41/50\n",
      "341/341 [==============================] - 176s 363ms/step - loss: 0.0097 - accuracy: 0.9965 - false_negatives_2: 24.0000 - false_positives_2: 14.0000 - val_loss: 0.2029 - val_accuracy: 0.9597 - val_false_negatives_2: 1.0000 - val_false_positives_2: 93.0000\n",
      "Epoch 42/50\n",
      "341/341 [==============================] - 176s 363ms/step - loss: 0.0114 - accuracy: 0.9963 - false_negatives_2: 25.0000 - false_positives_2: 15.0000 - val_loss: 0.0029 - val_accuracy: 0.9991 - val_false_negatives_2: 2.0000 - val_false_positives_2: 0.0000e+00\n",
      "Epoch 43/50\n",
      "341/341 [==============================] - 177s 363ms/step - loss: 0.0031 - accuracy: 0.9986 - false_negatives_2: 8.0000 - false_positives_2: 7.0000 - val_loss: 0.0042 - val_accuracy: 0.9991 - val_false_negatives_2: 0.0000e+00 - val_false_positives_2: 2.0000\n",
      "Epoch 44/50\n",
      "341/341 [==============================] - 176s 362ms/step - loss: 0.0096 - accuracy: 0.9972 - false_negatives_2: 17.0000 - false_positives_2: 14.0000 - val_loss: 0.0446 - val_accuracy: 0.9880 - val_false_negatives_2: 0.0000e+00 - val_false_positives_2: 28.0000\n",
      "Epoch 45/50\n",
      "341/341 [==============================] - 176s 360ms/step - loss: 0.0108 - accuracy: 0.9969 - false_negatives_2: 22.0000 - false_positives_2: 12.0000 - val_loss: 0.0252 - val_accuracy: 0.9906 - val_false_negatives_2: 1.0000 - val_false_positives_2: 21.0000\n",
      "Epoch 46/50\n",
      "341/341 [==============================] - 179s 371ms/step - loss: 0.0122 - accuracy: 0.9950 - false_negatives_2: 30.0000 - false_positives_2: 25.0000 - val_loss: 0.0086 - val_accuracy: 0.9970 - val_false_negatives_2: 6.0000 - val_false_positives_2: 1.0000\n",
      "Epoch 47/50\n",
      "341/341 [==============================] - 179s 368ms/step - loss: 0.0090 - accuracy: 0.9972 - false_negatives_2: 14.0000 - false_positives_2: 17.0000 - val_loss: 0.0229 - val_accuracy: 0.9919 - val_false_negatives_2: 4.0000 - val_false_positives_2: 15.0000\n",
      "Epoch 48/50\n",
      "341/341 [==============================] - 179s 367ms/step - loss: 0.0096 - accuracy: 0.9969 - false_negatives_2: 18.0000 - false_positives_2: 16.0000 - val_loss: 0.0066 - val_accuracy: 0.9974 - val_false_negatives_2: 0.0000e+00 - val_false_positives_2: 6.0000\n",
      "Epoch 49/50\n",
      "341/341 [==============================] - 181s 370ms/step - loss: 0.0034 - accuracy: 0.9991 - false_negatives_2: 6.0000 - false_positives_2: 4.0000 - val_loss: 4.7139e-04 - val_accuracy: 1.0000 - val_false_negatives_2: 0.0000e+00 - val_false_positives_2: 0.0000e+00\n",
      "Epoch 50/50\n",
      "341/341 [==============================] - 182s 371ms/step - loss: 0.0058 - accuracy: 0.9974 - false_negatives_2: 14.0000 - false_positives_2: 14.0000 - val_loss: 0.0229 - val_accuracy: 0.9923 - val_false_negatives_2: 4.0000 - val_false_positives_2: 14.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/MobileNetV1_CheckpointTest_scratch_epochs-50_batch-32\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/MobileNetV1_CheckpointTest_scratch_epochs-50_batch-32\\assets\n"
     ]
    }
   ],
   "source": [
    "for batchSize in batchSizes:\n",
    "    currentBatchSize = batchSize\n",
    "    for epochCount in epochCounts:\n",
    "        currentEpochCount = epochCount\n",
    "        trainModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment different batch sizes\n",
    "- Train the model with different batch sizes\n",
    "- batch sizes: `[8,16,32,64,128,256]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Params\n",
    "dataDir = \"../data/\"\n",
    "imgHeight = 224\n",
    "imgWidth = 224\n",
    "batchSizes = [8,16,32,64,128,256]\n",
    "\n",
    "shuffleSeed = 123\n",
    "\n",
    "transferLearning = False\n",
    "\n",
    "epochCounts = [10]\n",
    "\n",
    "currentBatchSize = batchSizes[0]\n",
    "currentEpochCount = epochCounts[0]\n",
    "\n",
    "modelName = \"MobileNetV1_BatchTest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Now Training: MobileNetV1_BatchTest_scratch_epochs-10_batch-8 --------\n",
      "Found 15561 files belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "1362/1362 [==============================] - 266s 129ms/step - loss: 0.3476 - accuracy: 0.8501 - false_negatives: 857.0000 - false_positives: 776.0000 - val_loss: 0.2680 - val_accuracy: 0.8946 - val_false_negatives: 33.0000 - val_false_positives: 213.0000\n",
      "Epoch 2/10\n",
      "1362/1362 [==============================] - 234s 108ms/step - loss: 0.2216 - accuracy: 0.9153 - false_negatives: 494.0000 - false_positives: 429.0000 - val_loss: 0.1877 - val_accuracy: 0.9289 - val_false_negatives: 132.0000 - val_false_positives: 34.0000\n",
      "Epoch 3/10\n",
      "1362/1362 [==============================] - 218s 105ms/step - loss: 0.1704 - accuracy: 0.9393 - false_negatives: 375.0000 - false_positives: 286.0000 - val_loss: 0.4127 - val_accuracy: 0.8252 - val_false_negatives: 238.0000 - val_false_positives: 170.0000\n",
      "Epoch 4/10\n",
      "1362/1362 [==============================] - 223s 110ms/step - loss: 0.1390 - accuracy: 0.9496 - false_negatives: 309.0000 - false_positives: 240.0000 - val_loss: 0.1147 - val_accuracy: 0.9537 - val_false_negatives: 23.0000 - val_false_positives: 85.0000\n",
      "Epoch 5/10\n",
      "1362/1362 [==============================] - 253s 125ms/step - loss: 0.1155 - accuracy: 0.9582 - false_negatives: 255.0000 - false_positives: 200.0000 - val_loss: 0.0703 - val_accuracy: 0.9751 - val_false_negatives: 46.0000 - val_false_positives: 12.0000\n",
      "Epoch 6/10\n",
      "1362/1362 [==============================] - 241s 127ms/step - loss: 0.1104 - accuracy: 0.9606 - false_negatives: 238.0000 - false_positives: 191.0000 - val_loss: 0.0798 - val_accuracy: 0.9730 - val_false_negatives: 14.0000 - val_false_positives: 49.0000\n",
      "Epoch 7/10\n",
      "1362/1362 [==============================] - 264s 134ms/step - loss: 0.0892 - accuracy: 0.9680 - false_negatives: 195.0000 - false_positives: 153.0000 - val_loss: 0.0556 - val_accuracy: 0.9803 - val_false_negatives: 42.0000 - val_false_positives: 4.0000\n",
      "Epoch 8/10\n",
      "1362/1362 [==============================] - 270s 125ms/step - loss: 0.0796 - accuracy: 0.9732 - false_negatives: 160.0000 - false_positives: 132.0000 - val_loss: 0.0645 - val_accuracy: 0.9760 - val_false_negatives: 12.0000 - val_false_positives: 44.0000\n",
      "Epoch 9/10\n",
      "1362/1362 [==============================] - 293s 142ms/step - loss: 0.0713 - accuracy: 0.9745 - false_negatives: 160.0000 - false_positives: 118.0000 - val_loss: 0.0720 - val_accuracy: 0.9734 - val_false_negatives: 9.0000 - val_false_positives: 53.0000\n",
      "Epoch 10/10\n",
      "1362/1362 [==============================] - 420s 232ms/step - loss: 0.0590 - accuracy: 0.9804 - false_negatives: 116.0000 - false_positives: 98.0000 - val_loss: 0.0373 - val_accuracy: 0.9854 - val_false_negatives: 23.0000 - val_false_positives: 11.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/MobileNetV1_BatchTest_scratch_epochs-10_batch-8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/MobileNetV1_BatchTest_scratch_epochs-10_batch-8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Now Training: MobileNetV1_BatchTest_scratch_epochs-10_batch-16 --------\n",
      "Found 15561 files belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "681/681 [==============================] - 475s 570ms/step - loss: 0.3500 - accuracy: 0.8500 - false_negatives_1: 848.0000 - false_positives_1: 786.0000 - val_loss: 0.5442 - val_accuracy: 0.7506 - val_false_negatives_1: 579.0000 - val_false_positives_1: 3.0000\n",
      "Epoch 2/10\n",
      "681/681 [==============================] - 451s 515ms/step - loss: 0.1912 - accuracy: 0.9241 - false_negatives_1: 474.0000 - false_positives_1: 353.0000 - val_loss: 0.2151 - val_accuracy: 0.9289 - val_false_negatives_1: 49.0000 - val_false_positives_1: 117.0000\n",
      "Epoch 3/10\n",
      "681/681 [==============================] - 392s 477ms/step - loss: 0.1457 - accuracy: 0.9461 - false_negatives_1: 344.0000 - false_positives_1: 243.0000 - val_loss: 0.3801 - val_accuracy: 0.8813 - val_false_negatives_1: 7.0000 - val_false_positives_1: 270.0000\n",
      "Epoch 4/10\n",
      "681/681 [==============================] - 328s 438ms/step - loss: 0.1258 - accuracy: 0.9531 - false_negatives_1: 300.0000 - false_positives_1: 211.0000 - val_loss: 0.0905 - val_accuracy: 0.9640 - val_false_negatives_1: 42.0000 - val_false_positives_1: 42.0000\n",
      "Epoch 5/10\n",
      "681/681 [==============================] - 343s 458ms/step - loss: 0.1002 - accuracy: 0.9636 - false_negatives_1: 231.0000 - false_positives_1: 166.0000 - val_loss: 0.2419 - val_accuracy: 0.9066 - val_false_negatives_1: 54.0000 - val_false_positives_1: 164.0000\n",
      "Epoch 6/10\n",
      "681/681 [==============================] - 330s 438ms/step - loss: 0.0961 - accuracy: 0.9667 - false_negatives_1: 214.0000 - false_positives_1: 149.0000 - val_loss: 0.1627 - val_accuracy: 0.9314 - val_false_negatives_1: 6.0000 - val_false_positives_1: 154.0000\n",
      "Epoch 7/10\n",
      "681/681 [==============================] - 333s 439ms/step - loss: 0.0813 - accuracy: 0.9699 - false_negatives_1: 199.0000 - false_positives_1: 129.0000 - val_loss: 0.0913 - val_accuracy: 0.9709 - val_false_negatives_1: 12.0000 - val_false_positives_1: 56.0000\n",
      "Epoch 8/10\n",
      "681/681 [==============================] - 329s 432ms/step - loss: 0.0772 - accuracy: 0.9717 - false_negatives_1: 180.0000 - false_positives_1: 128.0000 - val_loss: 0.2202 - val_accuracy: 0.9417 - val_false_negatives_1: 19.0000 - val_false_positives_1: 117.0000\n",
      "Epoch 9/10\n",
      "681/681 [==============================] - 343s 448ms/step - loss: 0.0733 - accuracy: 0.9735 - false_negatives_1: 164.0000 - false_positives_1: 125.0000 - val_loss: 0.1235 - val_accuracy: 0.9533 - val_false_negatives_1: 6.0000 - val_false_positives_1: 103.0000\n",
      "Epoch 10/10\n",
      "681/681 [==============================] - 342s 443ms/step - loss: 0.0552 - accuracy: 0.9802 - false_negatives_1: 128.0000 - false_positives_1: 88.0000 - val_loss: 0.0669 - val_accuracy: 0.9747 - val_false_negatives_1: 37.0000 - val_false_positives_1: 22.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/MobileNetV1_BatchTest_scratch_epochs-10_batch-16\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/MobileNetV1_BatchTest_scratch_epochs-10_batch-16\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Now Training: MobileNetV1_BatchTest_scratch_epochs-10_batch-32 --------\n",
      "Found 15561 files belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "341/341 [==============================] - 368s 936ms/step - loss: 0.3308 - accuracy: 0.8549 - false_negatives_2: 782.0000 - false_positives_2: 798.0000 - val_loss: 1.4535 - val_accuracy: 0.4537 - val_false_negatives_2: 1275.0000 - val_false_positives_2: 0.0000e+00\n",
      "Epoch 2/10\n",
      "341/341 [==============================] - 364s 937ms/step - loss: 0.1630 - accuracy: 0.9361 - false_negatives_2: 387.0000 - false_positives_2: 309.0000 - val_loss: 0.4745 - val_accuracy: 0.8423 - val_false_negatives_2: 357.0000 - val_false_positives_2: 11.0000\n",
      "Epoch 3/10\n",
      "341/341 [==============================] - 368s 943ms/step - loss: 0.1248 - accuracy: 0.9524 - false_negatives_2: 289.0000 - false_positives_2: 229.0000 - val_loss: 0.0889 - val_accuracy: 0.9674 - val_false_negatives_2: 28.0000 - val_false_positives_2: 48.0000\n",
      "Epoch 4/10\n",
      "341/341 [==============================] - 363s 926ms/step - loss: 0.1097 - accuracy: 0.9586 - false_negatives_2: 257.0000 - false_positives_2: 194.0000 - val_loss: 0.0787 - val_accuracy: 0.9751 - val_false_negatives_2: 30.0000 - val_false_positives_2: 28.0000\n",
      "Epoch 5/10\n",
      "341/341 [==============================] - 369s 941ms/step - loss: 0.0874 - accuracy: 0.9680 - false_negatives_2: 199.0000 - false_positives_2: 150.0000 - val_loss: 0.3043 - val_accuracy: 0.8950 - val_false_negatives_2: 3.0000 - val_false_positives_2: 242.0000\n",
      "Epoch 6/10\n",
      "341/341 [==============================] - 371s 944ms/step - loss: 0.0816 - accuracy: 0.9698 - false_negatives_2: 189.0000 - false_positives_2: 140.0000 - val_loss: 0.3180 - val_accuracy: 0.8775 - val_false_negatives_2: 6.0000 - val_false_positives_2: 280.0000\n",
      "Epoch 7/10\n",
      "341/341 [==============================] - 378s 963ms/step - loss: 0.0703 - accuracy: 0.9734 - false_negatives_2: 156.0000 - false_positives_2: 134.0000 - val_loss: 0.0917 - val_accuracy: 0.9632 - val_false_negatives_2: 17.0000 - val_false_positives_2: 69.0000\n",
      "Epoch 8/10\n",
      "341/341 [==============================] - 374s 950ms/step - loss: 0.0592 - accuracy: 0.9783 - false_negatives_2: 135.0000 - false_positives_2: 101.0000 - val_loss: 0.5542 - val_accuracy: 0.8535 - val_false_negatives_2: 1.0000 - val_false_positives_2: 341.0000\n",
      "Epoch 9/10\n",
      "341/341 [==============================] - 385s 982ms/step - loss: 0.0569 - accuracy: 0.9809 - false_negatives_2: 120.0000 - false_positives_2: 88.0000 - val_loss: 0.0549 - val_accuracy: 0.9820 - val_false_negatives_2: 9.0000 - val_false_positives_2: 33.0000\n",
      "Epoch 10/10\n",
      "341/341 [==============================] - 380s 966ms/step - loss: 0.0460 - accuracy: 0.9839 - false_negatives_2: 101.0000 - false_positives_2: 74.0000 - val_loss: 0.1354 - val_accuracy: 0.9550 - val_false_negatives_2: 1.0000 - val_false_positives_2: 104.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/MobileNetV1_BatchTest_scratch_epochs-10_batch-32\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/MobileNetV1_BatchTest_scratch_epochs-10_batch-32\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Now Training: MobileNetV1_BatchTest_scratch_epochs-10_batch-64 --------\n",
      "Found 15561 files belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "171/171 [==============================] - 420s 2s/step - loss: 0.3549 - accuracy: 0.8377 - false_negatives_3: 890.0000 - false_positives_3: 878.0000 - val_loss: 1.2319 - val_accuracy: 0.4537 - val_false_negatives_3: 1275.0000 - val_false_positives_3: 0.0000e+00\n",
      "Epoch 2/10\n",
      "171/171 [==============================] - 422s 2s/step - loss: 0.1935 - accuracy: 0.9240 - false_negatives_3: 463.0000 - false_positives_3: 365.0000 - val_loss: 2.0811 - val_accuracy: 0.4370 - val_false_negatives_3: 1314.0000 - val_false_positives_3: 0.0000e+00\n",
      "Epoch 3/10\n",
      "171/171 [==============================] - 425s 2s/step - loss: 0.1534 - accuracy: 0.9411 - false_negatives_3: 369.0000 - false_positives_3: 273.0000 - val_loss: 2.4862 - val_accuracy: 0.4447 - val_false_negatives_3: 1296.0000 - val_false_positives_3: 0.0000e+00\n",
      "Epoch 4/10\n",
      "171/171 [==============================] - 422s 2s/step - loss: 0.1255 - accuracy: 0.9535 - false_negatives_3: 304.0000 - false_positives_3: 203.0000 - val_loss: 0.6856 - val_accuracy: 0.7022 - val_false_negatives_3: 695.0000 - val_false_positives_3: 0.0000e+00\n",
      "Epoch 5/10\n",
      "171/171 [==============================] - 418s 2s/step - loss: 0.0967 - accuracy: 0.9638 - false_negatives_3: 224.0000 - false_positives_3: 170.0000 - val_loss: 0.3780 - val_accuracy: 0.8796 - val_false_negatives_3: 8.0000 - val_false_positives_3: 273.0000\n",
      "Epoch 6/10\n",
      "171/171 [==============================] - 424s 2s/step - loss: 0.0824 - accuracy: 0.9693 - false_negatives_3: 196.0000 - false_positives_3: 138.0000 - val_loss: 0.3266 - val_accuracy: 0.9087 - val_false_negatives_3: 7.0000 - val_false_positives_3: 206.0000\n",
      "Epoch 7/10\n",
      "171/171 [==============================] - 416s 2s/step - loss: 0.0752 - accuracy: 0.9730 - false_negatives_3: 162.0000 - false_positives_3: 132.0000 - val_loss: 0.3422 - val_accuracy: 0.8997 - val_false_negatives_3: 3.0000 - val_false_positives_3: 231.0000\n",
      "Epoch 8/10\n",
      "171/171 [==============================] - 429s 2s/step - loss: 0.0503 - accuracy: 0.9826 - false_negatives_3: 114.0000 - false_positives_3: 76.0000 - val_loss: 1.5734 - val_accuracy: 0.7425 - val_false_negatives_3: 1.0000 - val_false_positives_3: 600.0000\n",
      "Epoch 9/10\n",
      "171/171 [==============================] - 433s 2s/step - loss: 0.0700 - accuracy: 0.9735 - false_negatives_3: 166.0000 - false_positives_3: 123.0000 - val_loss: 0.7685 - val_accuracy: 0.8338 - val_false_negatives_3: 0.0000e+00 - val_false_positives_3: 388.0000\n",
      "Epoch 10/10\n",
      "171/171 [==============================] - 429s 2s/step - loss: 0.0393 - accuracy: 0.9864 - false_negatives_3: 78.0000 - false_positives_3: 70.0000 - val_loss: 0.0985 - val_accuracy: 0.9632 - val_false_negatives_3: 9.0000 - val_false_positives_3: 77.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/MobileNetV1_BatchTest_scratch_epochs-10_batch-64\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/MobileNetV1_BatchTest_scratch_epochs-10_batch-64\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Now Training: MobileNetV1_BatchTest_scratch_epochs-10_batch-128 --------\n",
      "Found 15561 files belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "86/86 [==============================] - 462s 5s/step - loss: 0.3719 - accuracy: 0.8313 - false_negatives_4: 888.0000 - false_positives_4: 949.0000 - val_loss: 0.9931 - val_accuracy: 0.4537 - val_false_negatives_4: 1275.0000 - val_false_positives_4: 0.0000e+00\n",
      "Epoch 2/10\n",
      "86/86 [==============================] - 444s 4s/step - loss: 0.1819 - accuracy: 0.9265 - false_negatives_4: 458.0000 - false_positives_4: 343.0000 - val_loss: 1.9348 - val_accuracy: 0.4370 - val_false_negatives_4: 1314.0000 - val_false_positives_4: 0.0000e+00\n",
      "Epoch 3/10\n",
      "86/86 [==============================] - 444s 4s/step - loss: 0.1431 - accuracy: 0.9461 - false_negatives_4: 351.0000 - false_positives_4: 236.0000 - val_loss: 2.3191 - val_accuracy: 0.4447 - val_false_negatives_4: 1296.0000 - val_false_positives_4: 0.0000e+00\n",
      "Epoch 4/10\n",
      "86/86 [==============================] - 451s 5s/step - loss: 0.1111 - accuracy: 0.9573 - false_negatives_4: 280.0000 - false_positives_4: 185.0000 - val_loss: 2.8728 - val_accuracy: 0.4404 - val_false_negatives_4: 1306.0000 - val_false_positives_4: 0.0000e+00\n",
      "Epoch 5/10\n",
      "86/86 [==============================] - 454s 5s/step - loss: 0.0970 - accuracy: 0.9631 - false_negatives_4: 213.0000 - false_positives_4: 189.0000 - val_loss: 3.4178 - val_accuracy: 0.4640 - val_false_negatives_4: 1251.0000 - val_false_positives_4: 0.0000e+00\n",
      "Epoch 6/10\n",
      "86/86 [==============================] - 460s 5s/step - loss: 0.0939 - accuracy: 0.9673 - false_negatives_4: 208.0000 - false_positives_4: 148.0000 - val_loss: 3.6137 - val_accuracy: 0.4632 - val_false_negatives_4: 1253.0000 - val_false_positives_4: 0.0000e+00\n",
      "Epoch 7/10\n",
      "86/86 [==============================] - 458s 5s/step - loss: 0.0798 - accuracy: 0.9691 - false_negatives_4: 176.0000 - false_positives_4: 161.0000 - val_loss: 1.6159 - val_accuracy: 0.4554 - val_false_negatives_4: 1271.0000 - val_false_positives_4: 0.0000e+00\n",
      "Epoch 8/10\n",
      "86/86 [==============================] - 448s 4s/step - loss: 0.0476 - accuracy: 0.9818 - false_negatives_4: 118.0000 - false_positives_4: 80.0000 - val_loss: 0.3017 - val_accuracy: 0.8890 - val_false_negatives_4: 258.0000 - val_false_positives_4: 1.0000\n",
      "Epoch 9/10\n",
      "86/86 [==============================] - 452s 5s/step - loss: 0.0736 - accuracy: 0.9743 - false_negatives_4: 156.0000 - false_positives_4: 124.0000 - val_loss: 0.0631 - val_accuracy: 0.9764 - val_false_negatives_4: 30.0000 - val_false_positives_4: 25.0000\n",
      "Epoch 10/10\n",
      "86/86 [==============================] - 453s 5s/step - loss: 0.0381 - accuracy: 0.9865 - false_negatives_4: 90.0000 - false_positives_4: 57.0000 - val_loss: 0.0496 - val_accuracy: 0.9846 - val_false_negatives_4: 5.0000 - val_false_positives_4: 31.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/MobileNetV1_BatchTest_scratch_epochs-10_batch-128\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/MobileNetV1_BatchTest_scratch_epochs-10_batch-128\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Now Training: MobileNetV1_BatchTest_scratch_epochs-10_batch-256 --------\n",
      "Found 15561 files belonging to 2 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_5/mobilenet_1.00_224/conv_pw_3/Conv2D' defined at (most recent call last):\n    File \"C:\\Users\\nikla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\nikla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\traitlets\\config\\application.py\", line 982, in launch_instance\n      app.start()\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\nikla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\Users\\nikla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\Users\\nikla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\nikla\\AppData\\Local\\Temp\\ipykernel_12744\\3376906410.py\", line 5, in <module>\n      trainModel()\n    File \"C:\\Users\\nikla\\AppData\\Local\\Temp\\ipykernel_12744\\3526589008.py\", line 21, in trainModel\n      model.fit(train_ds,\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 283, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 255, in convolution_op\n      return tf.nn.convolution(\nNode: 'model_5/mobilenet_1.00_224/conv_pw_3/Conv2D'\nOOM when allocating tensor with shape[256,128,56,56] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_5/mobilenet_1.00_224/conv_pw_3/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1142052]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [11], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m epochCount \u001b[39min\u001b[39;00m epochCounts:\n\u001b[0;32m      4\u001b[0m     currentEpochCount \u001b[39m=\u001b[39m epochCount\n\u001b[1;32m----> 5\u001b[0m     trainModel()\n",
      "Cell \u001b[1;32mIn [10], line 21\u001b[0m, in \u001b[0;36mtrainModel\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39m#model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m#    filepath=checkpoint_filepath,\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m#    save_weights_only=True)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(),\n\u001b[0;32m     19\u001b[0m           loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mBinaryCrossentropy(),\n\u001b[0;32m     20\u001b[0m           metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mFalseNegatives(), tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mFalsePositives()])\n\u001b[1;32m---> 21\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_ds,\n\u001b[0;32m     22\u001b[0m                 epochs\u001b[39m=\u001b[39;49mcurrentEpochCount,\n\u001b[0;32m     23\u001b[0m                 validation_data\u001b[39m=\u001b[39;49mval_ds,\n\u001b[0;32m     24\u001b[0m                 callbacks\u001b[39m=\u001b[39;49m[tensorboard_callback])\n\u001b[0;32m     25\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39m../models/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m buildRunName(modelName, transferLearning, currentEpochCount, currentBatchSize))\n\u001b[0;32m     26\u001b[0m end_time \u001b[39m=\u001b[39m time()\n",
      "File \u001b[1;32ml:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32ml:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_5/mobilenet_1.00_224/conv_pw_3/Conv2D' defined at (most recent call last):\n    File \"C:\\Users\\nikla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\nikla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\traitlets\\config\\application.py\", line 982, in launch_instance\n      app.start()\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\nikla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\Users\\nikla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\Users\\nikla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\nikla\\AppData\\Local\\Temp\\ipykernel_12744\\3376906410.py\", line 5, in <module>\n      trainModel()\n    File \"C:\\Users\\nikla\\AppData\\Local\\Temp\\ipykernel_12744\\3526589008.py\", line 21, in trainModel\n      model.fit(train_ds,\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 283, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"l:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVision\\.env\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 255, in convolution_op\n      return tf.nn.convolution(\nNode: 'model_5/mobilenet_1.00_224/conv_pw_3/Conv2D'\nOOM when allocating tensor with shape[256,128,56,56] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_5/mobilenet_1.00_224/conv_pw_3/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1142052]"
     ]
    }
   ],
   "source": [
    "for batchSize in batchSizes:\n",
    "    currentBatchSize = batchSize\n",
    "    for epochCount in epochCounts:\n",
    "        currentEpochCount = epochCount\n",
    "        trainModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "- Model loaded with imageNet weights\n",
    "- base model frozen\n",
    "- only GlobalAveragePooling2D and Dense trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Params\n",
    "dataDir = \"../data/\"\n",
    "imgHeight = 224\n",
    "imgWidth = 224\n",
    "batchSizes = [32]\n",
    "\n",
    "shuffleSeed = 123\n",
    "\n",
    "transferLearning = True\n",
    "\n",
    "epochCounts = [5,10]\n",
    "\n",
    "currentBatchSize = batchSizes[0]\n",
    "currentEpochCount = epochCounts[0]\n",
    "\n",
    "modelName = \"MobileNetV1_TL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Now Training: MobileNetV1_TL_transfer_epochs-5_batch-32 --------\n",
      "Found 15561 files belonging to 2 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
      "17225924/17225924 [==============================] - 9s 1us/step\n",
      "Epoch 1/5\n",
      "341/341 [==============================] - 102s 198ms/step - loss: 0.0623 - accuracy: 0.9810 - false_negatives_3: 117.0000 - false_positives_3: 90.0000 - val_loss: 0.0111 - val_accuracy: 0.9974 - val_false_negatives_3: 6.0000 - val_false_positives_3: 0.0000e+00\n",
      "Epoch 2/5\n",
      "341/341 [==============================] - 103s 201ms/step - loss: 0.0093 - accuracy: 0.9985 - false_negatives_3: 11.0000 - false_positives_3: 5.0000 - val_loss: 0.0065 - val_accuracy: 0.9983 - val_false_negatives_3: 3.0000 - val_false_positives_3: 1.0000\n",
      "Epoch 3/5\n",
      "341/341 [==============================] - 107s 209ms/step - loss: 0.0059 - accuracy: 0.9991 - false_negatives_3: 9.0000 - false_positives_3: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9983 - val_false_negatives_3: 3.0000 - val_false_positives_3: 1.0000\n",
      "Epoch 4/5\n",
      "341/341 [==============================] - 113s 222ms/step - loss: 0.0045 - accuracy: 0.9992 - false_negatives_3: 7.0000 - false_positives_3: 2.0000 - val_loss: 0.0020 - val_accuracy: 1.0000 - val_false_negatives_3: 0.0000e+00 - val_false_positives_3: 0.0000e+00\n",
      "Epoch 5/5\n",
      "341/341 [==============================] - 119s 226ms/step - loss: 0.0036 - accuracy: 0.9992 - false_negatives_3: 5.0000 - false_positives_3: 4.0000 - val_loss: 0.0016 - val_accuracy: 0.9996 - val_false_negatives_3: 1.0000 - val_false_positives_3: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/MobileNetV1_TL_transfer_epochs-5_batch-32\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/MobileNetV1_TL_transfer_epochs-5_batch-32\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Now Training: MobileNetV1_TL_transfer_epochs-10_batch-32 --------\n",
      "Found 15561 files belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "341/341 [==============================] - 124s 233ms/step - loss: 0.0508 - accuracy: 0.9858 - false_negatives_4: 75.0000 - false_positives_4: 80.0000 - val_loss: 0.0094 - val_accuracy: 0.9974 - val_false_negatives_4: 4.0000 - val_false_positives_4: 2.0000\n",
      "Epoch 2/10\n",
      "341/341 [==============================] - 125s 239ms/step - loss: 0.0082 - accuracy: 0.9985 - false_negatives_4: 12.0000 - false_positives_4: 4.0000 - val_loss: 0.0058 - val_accuracy: 0.9983 - val_false_negatives_4: 3.0000 - val_false_positives_4: 1.0000\n",
      "Epoch 3/10\n",
      "341/341 [==============================] - 128s 244ms/step - loss: 0.0055 - accuracy: 0.9986 - false_negatives_4: 11.0000 - false_positives_4: 4.0000 - val_loss: 0.0043 - val_accuracy: 0.9987 - val_false_negatives_4: 3.0000 - val_false_positives_4: 0.0000e+00\n",
      "Epoch 4/10\n",
      "341/341 [==============================] - 134s 256ms/step - loss: 0.0037 - accuracy: 0.9993 - false_negatives_4: 6.0000 - false_positives_4: 2.0000 - val_loss: 0.0017 - val_accuracy: 0.9996 - val_false_negatives_4: 1.0000 - val_false_positives_4: 0.0000e+00\n",
      "Epoch 5/10\n",
      "341/341 [==============================] - 134s 250ms/step - loss: 0.0036 - accuracy: 0.9994 - false_negatives_4: 6.0000 - false_positives_4: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000 - val_false_negatives_4: 0.0000e+00 - val_false_positives_4: 0.0000e+00\n",
      "Epoch 6/10\n",
      "341/341 [==============================] - 134s 254ms/step - loss: 0.0022 - accuracy: 0.9995 - false_negatives_4: 4.0000 - false_positives_4: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000 - val_false_negatives_4: 0.0000e+00 - val_false_positives_4: 0.0000e+00\n",
      "Epoch 7/10\n",
      "341/341 [==============================] - 136s 258ms/step - loss: 0.0019 - accuracy: 0.9995 - false_negatives_4: 3.0000 - false_positives_4: 2.0000 - val_loss: 6.2409e-04 - val_accuracy: 1.0000 - val_false_negatives_4: 0.0000e+00 - val_false_positives_4: 0.0000e+00\n",
      "Epoch 8/10\n",
      "341/341 [==============================] - 139s 261ms/step - loss: 0.0020 - accuracy: 0.9995 - false_negatives_4: 3.0000 - false_positives_4: 2.0000 - val_loss: 6.9860e-04 - val_accuracy: 1.0000 - val_false_negatives_4: 0.0000e+00 - val_false_positives_4: 0.0000e+00\n",
      "Epoch 9/10\n",
      "341/341 [==============================] - 141s 265ms/step - loss: 0.0017 - accuracy: 0.9997 - false_negatives_4: 3.0000 - false_positives_4: 0.0000e+00 - val_loss: 5.6604e-04 - val_accuracy: 1.0000 - val_false_negatives_4: 0.0000e+00 - val_false_positives_4: 0.0000e+00\n",
      "Epoch 10/10\n",
      "341/341 [==============================] - 336s 828ms/step - loss: 0.0011 - accuracy: 0.9998 - false_negatives_4: 1.0000 - false_positives_4: 1.0000 - val_loss: 3.3462e-04 - val_accuracy: 1.0000 - val_false_negatives_4: 0.0000e+00 - val_false_positives_4: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/MobileNetV1_TL_transfer_epochs-10_batch-32\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/MobileNetV1_TL_transfer_epochs-10_batch-32\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Now Training: MobileNetV1_TL_transfer_epochs-15_batch-32 --------\n",
      "Found 15561 files belonging to 2 classes.\n",
      "Epoch 1/15\n"
     ]
    }
   ],
   "source": [
    "for batchSize in batchSizes:\n",
    "    currentBatchSize = batchSize\n",
    "    for epochCount in epochCounts:\n",
    "        currentEpochCount = epochCount\n",
    "        trainModel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "050a86c1e49b50a939c7f1648b7e57d527ba12504a9b8cc8c9f6f359e0405f48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
